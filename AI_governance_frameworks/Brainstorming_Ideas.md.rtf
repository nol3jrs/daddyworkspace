{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 - **Structuring AI Agents Like a Corporate Hierarchy**: Organize agents into departments (R&D for research/reports via Perplexity; HR for ethics/onboarding; Finance for budgeting; IT for ops/workflows; CEO for oversight/foresight), with you as the board/owner setting vision, and agents chaining tasks hierarchically with shared memory to avoid drift.\
- **Sourcing and Customizing Mission Statements**: Download and compile mission statements from sites like danmartell.com/resources, openai.com/safety, alignmentforum.org, forum.effectivealtruism.org, and martellventures.com/apply; mix them (e.g., "hunt novel insights, verify relentlessly") into custom prompts for agents, combining for best use cases like ethics guardrails or tool testing.\
- **Testing and Iterating Agent Behaviors**: Simulate employee tasks with 7-day test loops; refine statements until agents behave like humans (e.g., pick two tools, test, choose organic fit); use human baselines for difficulty (5 mins to 16+ hours) and aim for autonomy comparable to 30-min human work.\
- **Incorporating Safety and Alignment Principles**: Integrate principles like "never assist in harm, prioritize safety" from OpenAI's Preparedness Framework; add visibility (identifiers, monitoring), interruptibility, and ethical evals from agentic governance docs to prevent risks like replication or misinformation.\
- **Evaluation Thresholds for Capabilities**: Brainstorm evals for dangerous capabilities (persuasion, cyber, proliferation); set replication thresholds (basic for illicit gain $2-10M start, flexible for hacking, robust for independent ops >$100M revenue); use continuous scales from METR/Open Philanthropy for forecasting 2025-2029 progress.\
- **Workflow Automation and Habit Stacking**: Audit energy-sucking tasks; automate via AI (e.g., habit stack prompting after reading); become a "director" with vision/taste/EQ; apply Dan Martell's rhythm (daily consumption, weekly masterminds, monthly audits, quarterly events) to agent dev.\
- **Sociotechnical and Ethical Deployment**: Ensure equity/privacy in user interactions; address societal impacts (cooperation, economic displacement, environment); invest in holistic evals (human-AI, multi-agent, societal) from Ethics of AI Assistants and Foundational Challenges docs.\
- **Scaling and Risk Mitigation**: Modular agents for chained tasks; identify choke points (AML, data centers) to bound harms; amplify cyber offense but prioritize R&D evals for >$1T damages; test for robustness to shutdown in autonomous loops.\
- **File-Based Knowledge Base for Workspace**: Create multiple .md/.txt files (e.g., missions by dept, safety principles, evals, dev tips) for upload to Grok Workspace; leverage for governance (as constitution prompts) and brainstorming (query for custom agents or refinements).}